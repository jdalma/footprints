
# 1장. 발행/구독 메시지 전달

데이터의 기본 단위는 **메시지**이며, 카프카 입장에서는 단순히 바이트의 배열일 뿐이다.  
이 메시지는 **키**라 불리는 메시지를 저장할 파티션을 결정하기 위해 사용되는 메타데이터를 포함할 수도 있다.  

카프카는 효율성을 위해 같은 토픽의 파티션에 쓰여지는 메시지들의 집합인 배치단위로 저장한다.  
(이런 배치는 지연과 처리량 사이에 트레이드 오프가 발생하긴 한다.)  

## 토픽과 파티션

카프카에 저장되는 메시지는 **토픽**단위로 분류된다. (DB의 테이블이나 파일시스템의 폴더..)  
이 토픽은 다시 여러 개의 **파티션**으로 나뉘어진다.  

커밋 로그의 관점으로 보면 파티션은 하나의 로그에 해당한다.  
파티션에 메세지가 쓰여질 때는 추가만 가능한 (append-only) 형태로 쓰여지며, 읽을 때는 맨 앞부터 제일 끝까지의 순서로 읽힌다.  
대개 토픽안에 여러 개의 파티션이 있는 만큼 토픽 안의 메시지 전체에 대해 순서는 보장되지 않으며, 단일 파티션 안에서만 순서가 보장될 뿐이다.  

## 프로듀서와 컨슈머, 브로커

- **프로듀서**
  - 메시지를 생성
  - 특정한 파티션을 지정해서 메시지를 쓰기도 하고, 파티셔너를 통해 파티션으로 대응시키기도 한다. (커스텀도 가능하다)
- **컨슈머**
  - 메시지를 읽음
  - 1개 이상의 토픽을 구독하여 저장된 메시지들을 각 파티션에 쓰여진 순서대로 읽어 간다.
  - 파티션의 각 메시지는 고유한 오프셋을 가지며, 뒤에 오는 메시지의 오프셋이 항상 크다.
  - 파티션별로 다음 번에 사용 가능한 오프셋 값을 저장해놓는다.
  - 컨슈머에서 파티션으로의 대응 관계는 컨슈머의 파티션 소유권이라고도 부른다.
- **컨슈머 그룹**
  - 컨슈머가 이 그룹의 일원으로서 작동한다.
  - 이 그룹은 토픽에 저장된 데이터를 읽어오기 위해 협업하는 하나 이상의 컨슈머로 이루어진다.
  - 각 파티션이 하나의 컨슈머에 의해서만 읽히도록 보장한다.
- **브로커**
  - 프로듀서로부터 메시지를 전달받아 오프셋을 할당한뒤 디스크 저장소에 쓴다.
  - 메시지를 저장할 때 각각의 메시지에 지속적으로 증가하는 메타데이터 정수값(오프셋)을 부여한다.
  - 메시지를 지속성있게 보관하는 보존 기능이 설정되어 있다. (기간, 파티션의 크기가 특정 사이즈에 도달하는 경우 등)

# 2장. 카프카 설치하기

카프카 클러스터의 메타데이터와 컨슈머 클라이언트에 대한 정보를 저장하기 위해 아파치 주키퍼를 사용한다.  
주키퍼는 설정 정보 관리, 이름 부여, 분산 동기화, 그룹 서비스를 제공하는 중앙화된 서비스이다.  

- 주키퍼 앙상블?
- 파티션 의사결정?
- 하드웨어 및 네트워크 고려?

# 3장. 카프카 프로듀서

프로듀서 `토픽,(파티션 optional),(키 optional),밸류` -> 시리얼라이저 -> 파티셔너 -> 토픽 A의 N번 파티션  
저장에 실패하면 재시도하거나 재시도 할 수 없으면 예외발생, 성공하면 Metadata를 리턴한다.  
이렇게 저장 요청된 메세지들은 전송될 토픽과 파티션이 확정되면 `레코드 배치`에 추가되며, 별도의 스레드가 카프카 브로커에게 전송한다.  
  
**카프카 프로듀서 생성하기**
1. bootstrap.servers : 브로커의 `host:port` 목록
2. key.serializer : 카프카에 쓸 레코드의 키의 값을 직렬화하기 위해 사용되는 시리얼라이저 클래스 이름
3. value.serializer : 카프카에 쓸 레코드의 밸류값을 직렬화하기 위해 사용되는 시리얼라이저 클래스 이름

**전송방법**
1. fire and forget : 성공 혹은 실패 여부를 신경쓰지 않는다.프로듀서는 자동으로 전송 실패한 메시지를 재전송 시도하기 때문에 대부분의 경우 성공적으로 전달되지만, 재시도를 할 수 없는 에러가 발생하거나 타임아웃이 발생했을 경우 메시지는 유실될 수 있다.
2. synchronous send : `send()`는 Future 객체를 리턴하지만 다음 메세지를 전송하기 전 `get()`을 호출해서 작업이 완료될 때 까지 기다려야 성공 여부를 확인할 수 있다.
3. asynchronous send : 콜백 함수와 함께 `send()`를 호출하면 카프카 브로커로부터 응답을 받는 시점에 콜백 함수가 호출되도록 지정할 수 있다.

## 메시지 전달하면서 발생할 수 있는 에러 케이스

1. SerializationException
2. 카프카 메시지 버퍼가 가득찬 경우 TimeoutException
3. 전송 작업을 수행하는 스레드에 인터럽트가 걸리는 InterruptException
4. 동기적으로 메세지를 전송하는 경우 `producer.send(record).get()` 코드에서 카프카로 성공적으로 전송되지 않았을 경우 `Future.get()`에서 예외가 발생

재시도 가능한 예외와 재시도가 불가능한 예외를 구분해야한다.  
(비동기 전송에서도 콜백을 지정하여 전송에 성공했는지 실패했는지 알 수 있다.)  

> 콜백은 프로듀서의 메인 스레드에서 실행되기에 두 개의 메시지를 동일한 파티션에 전송하면 콜백 역시 보낸 순서대로 실행된다.
> 하지만 프로듀서가 지연되는 상황을 막기 위해서는 콜백도 충분히 빨라야 한다는 의미가 된다. 그렇기에 콜백안에서 블로킹 작업을 수행하는것 역시 권장되지 않는다.

## 메시지 전달 시간

ProducerRecord를 보낼 때 걸리는 시간을 두 구간으로 나눌 수 있다.
**`send()`에 대한 비동기 호출이 이뤄진 시각부터 결과를 리턴할 때 까지 걸리는 시간** : send를 호출한 스레드는 블록된다.
**`send()`에 대한 비동기 호출이 성공적으로 리턴한 시각부터 콜백이 호출될 때까지 걸리는 시간** : 배치에 메세지가 추가된 시점에서부터 카프카가 성공 응답을 보내거나, 재시도 불가능한 실패가 일어나거나, 아니면 전송을 위해 할당된 시간이 소진될 때까지의 시간과 동일하다.

1. `max.block.ms` : 프로듀서가 얼마나 오랫동안 블록되었는지
2. `delivery.timeout.ms` : 비동기 send가 문제없이 리턴되고 레코드가 배치에 저장된 시점부터 브로커의 응답을 받거나 아니면 전송을 포기하게 되는 시점까지의 제한시간을 결정한다. 이 값은 linger.ms, request.timeout.ms 보다 커야 한다.
    - 만약 재시도를 하는 도중 delivery.timeout.ms를 넘어가버린다면 마지막으로 재시도하기 전에 예외와 함께 콜백이 호출된다.
    - 레코드 배치가 전송을 기다리는 와중에 delivery.timeout.ms를 넘어가버려도 예외와 함께 콜백이 호출된다.
3. `request.timeout.ms` : 프로듀서가 데이터를 전송할 때 서버로부터 응답을 받기 위해 얼마나 기다릴 것인지를 결정. 불필요한 재시도로 인한 메세지 중복 가능성을 줄이려면 `replica.lag.time.max.ms` (브로커 설정)보다 커야 한다.
4. `retries`, `retry.backoff.ms` : 프로듀서가 서버로부터 에러 메세지를 받았을 때 이것이 일시적인 에러일 수 있다. 이때 retries가 프로듀서가 메시지 전송을 포기하고 에러를 발생시킬때 까지 재전송하는 횟수를 말한다. 이 재시도 사이 간격을 retry.backoff.ms로 조정할 수 있다.
    - retries가 0보다 크고 max.in.flight.requests.per.connection도 0보다 크면 메세지 순서가 뒤집어질 수 있다.
6. `linger.ms` : 배치를 전송하기 전까지 대기하는 시간을 결정한다. KafkaProducer는 배치가 가득 차거나 linger.ms에 설정된 제한 시간이 되었을 때 메시지 배치를 전송한다. (기본적으로 메시지 전송에 사용할 수 있는 스레드가 있을 때 곧바로 전송하도록 되어 있다.)
7. `compression.type` : 압축 알고리즘 (snappy, gzip, lz4, zstd)
8. `batch.size` : 각각의 배치에 사용될 메모리의 양을 결정한다. 단위는 메시지의 개수가 아니라 바이트이다.
9. `enable.idempotence` : 브로커가 프로듀서로부터 메세지를 받고 정상처리한 이후 응답을 반환하기 전에 브로커에 장애가 발생하는 경우 프로듀서는 메세지를 재전송하기에 메세지가 중복되어 저장될 수 있다. 이 경우를 방지하기 위함이다.
    - 이 기능을 활성화하면 프로듀서는 레코드를 보낼 때마다 순차적인 번호를 붙여서 보내게 된다. 브로커가 동일한 번호를 가진 레코드를 2개 이상 받을 경우 하나만 저장하게 되며, 프로듀서는 DuplicateSequenceException을 받게 된다.

## 쿼터 스로틀링

카프카 브로커에는 쓰기/읽기 속도를 한도(쿼터)를 설정하여 제한할 수 있다.

1. 쓰기, 쿼터 : 데이터를 전송하거나 받는 속도
3. 요청 쿼터 : 브로커가 요청을 처리하는 시간 비율 단위로 제한

또한 스로틀링을 설정하여 클라이언트가 전송하는 할당량을 제어할 수 있다.

# 4장. 카프카 컨슈머

프로듀서의 공급 속도가 컨슈머의 소비속도보다 빠르다면 처리가 밀리거나 저장공간을 넘어설 수 있기 때문에 여러 컨슈머가 같은 토픽으로 데이터를 분할해서 읽어올 수 있게 해야한다.  
컨슈머는 컨슈머 그룹에 속하며, 동일한 컨슈머 그룹에 속한 각각의 컨슈머들은 그룹이 구독하는 토픽에서 서로 다른 파티션의 메세지를 받아온다.  

> 만약 하나의 토픽을 구독하는 하나의 컨슈머 그룹에 파티션 수보다 더 많은 컨슈머를 추가한다면, 컨슈머 중 몇몇은 유휴 상태가 되어 메세지를 전혀 받지 못한다.

**파티션 리밸런싱 케이스** 
컨슈머들은 자신들이 구독하는 토픽의 파티션들에 소유권을 공유하기에 이 소유권을 재할당하는 작업을 리밸런싱이라고 한다.  
1. 컨슈머 그룹에 새로운 컨슈머를 추가
2. 컨슈머가 종료되거나 크래시나는 경우
3. 토픽에 새 파티션이 추가된 경우

## 컨슈머 지정

소비할 토픽 이름을 정규식 표현으로 지정해줄 수도 있다.  
**컨슈머 API의 핵심은 서버에 추가 데이터가 들어왔는지 폴링하는 단순한 루프다.** 컨슈머는 카프카를 계속해서 폴링하지 않으면 죽은 것으로 간주된다. (max.poll.interval.ms에서 지정된 시간 이상으로 호출되지 않을 경우)  
([KakfaConsumer](https://github.com/apache/kafka/blob/trunk/examples/src/main/java/kafka/examples/Consumer.java)에는 1초간 폴링한다.)  

## 스레드 안전성

하나의 스레드에서 동일한 그룹 내에 여러 개의 컨슈머를 생성할 수는 없으며, 같은 컨슈머를 다수의 스레드가 안전하게 사용할 수도 없다.  
즉, `1 스레드 = 1 컨슈머`가 원칙이다.  
컨슈머 로직을 자체적인 객체로 감싼 다음 ExecutorService를 사용해서 각자의 컨슈머를 가지는 다수의 스레드를 시작시키면 좋다.  
워커 스레드 패턴을 이용하는 방법도 좋다. [예제](https://www.confluent.io/blog/kafka-consumer-multi-threaded-messaging/)  

## 연결 유지

1. `sesstion.timeout.ms`와 `heartbeat.interval.ms`
2. `max.poll.interval.ms` : 컨슈머가 폴링을 하지 않고도 죽은 것으로 판정되지 않을 수 있는 최대 시간을 지정할 수 있음

## 오프셋과 커밋

파티션에서의 현재 위치를 업데이트하는 작업을 오프셋 커밋이라고 부른다.  
레코드를 개별적으로 커밋하지 않는다. 대신, 컨슈머는 파티션에서 성공적으로 처리해 낸 마지막 메세지를 커밋하여 앞의 메시지를 성공적으로 처리했다고 암묵적으로 처리한다.  
컨슈머는 `__consumer_offsets`라는 특수 토픽을 이용하여 오프셋을 커밋한다.  

만약 커밋된 오프셋과 클라이언트가 실제로 처리한 메시지의 오프셋이 다른 경우 처리가 누락되거나 2번 처리될 수 있다.  
이를 방지하기 위해 KafkaConsumer API는 오프셋을 커밋하는 다양한 방법을 지원한다.  

1. **자동 커밋** : `enable.auto.commit`을 활성화하면 컨슈머가 대신 5초(auto.commit.interval.ms)에 한 번, poll을 통해 받은 메시지 중 마지막 메시지의 오프셋을 커밋한다. `poll()`이 호출될 때마다 매번 확인하며 커밋해야할 경우에는 이전에 호출된 `poll()`의 오프셋 결과를 기준으로 커밋한다.
2. **명시적 커밋** : `enable.auto.commit`을 비활성화 하여 `commitSync()`로 오프셋 커밋을 명시할 수 있다. `poll()`에 의해 리턴된 마지막 오프셋을 커밋하기에 모든 레코드가 처리되기 전 커밋하면 누락할 가능성이 있다.
3. **비동기적 커밋** : 명시적 커밋은 브로커가 커밋 요청에 응답할 때까지 애플리케이션이 블록된다는 점이다. 오프셋 커밋 순서 관련된 문제에 주의를 기울이는 것이 좋다.
4. **동기적 커밋과 비동기적 커밋 함께 사용하기** : 컨슈머를 닫기 전 혹은 리밸런스 전 마지막 커밋이라면, 성공 여부를 추가로 확인할 필요가 있다. 정상적인 상황에서는 `commitAsync()`사용, 컨슈머를 닫는 상황에서는 `commitSync()` 사용
5. **특정 오프셋 커밋하기** : 큰 배치를 작업하는 경우 오프셋을 직접 커밋하고 싶을 수 있다.
6. **리밸런스 리스너** : 컨슈머에 할당된 파티션이 해제될 것이라는 걸 알게 된다면 해당 파티션에서 마지막으로 처리한 이벤트의 오프셋을 커밋해야 한다. 

## 독립 실행 컨슈머 : 컨슈머 그룹 없이 컨슈머를 사용해야 하는 이유와 방법

컨슈머 그룹은 컨슈머들에게 파티션을 자동으로 할당해주고 해당 그룹에 컨슈머가 추가되거나 제거될 경우 자동으로 리밸런싱을 해준다.  
하지만 하나의 컨슈머가 토픽의 모든 파티션으로부터 모든 데이터를 읽어와야 하거나, 토픽의 특정 파티션으로부터 데이터를 읽어와야 하는 간단한 요구사항이 있을 때 사용할 수 있다.  
만약 토픽에 새로운 파티션이 추가되는 경우 컨슈머에게 알림이 가지 않기에, 주기적으로 `consumer.partitionsFor()`를 호출해서 파티션 정보를 확인하거나 아니면 애플리케이션을 재시작하여 대처할 필요가 있다.


## 궁금증

1. 오프셋 커밋
    - 오프셋 커밋이 정상적으로 수행되기 전에 만약 브로커에서 장애가 발생하면 메세지가 중복으로 소비될 수 있다.
2. 메시지의 순서가 중요한 경우
    - 주문 -> 피킹 -> 패킹 -> 출고 같이 메시지의 순서가 중요하다면 토픽을 이벤트별로 분리하고 파티션을 주무번호로 나누는 것이 어떨까? 파티션에 리밸런싱이 발생하면 순서가 어긋나는 경우가 있을 것이기 때문이다.
    - 단일 파티션 + 단일 컨슈머
    - 수동 파티션 할당으로 리밸런싱 방지
    - 상태 기반 멱등성 구현
4. 정적 그룹 멤버십
5. 리밸런싱이 발생하는 경우
    - 파티션이 늘어나거나 줄어드는 경우
    - 컨슈머에 장애가 발생하여 연결이 끊기거나 컨슈머가 컨슈머 그룹에 추가되는 경우

```
// 시나리오:
// 1. Consumer-A가 CREATE(100) 처리 시작
// 2. 처리 중에 새 컨슈머 추가 → 리밸런싱 발생
// 3. Consumer-A 중단, 오프셋 미커밋 (여전히 99)
// 4. 리밸런싱 완료 후 Consumer-B가 Partition-0 할당받음
// 5. Consumer-B가 offset 100부터 다시 시작

// 결과: CREATE가 중복 처리되거나, 
//       UPDATE/CANCEL이 CREATE보다 먼저 처리될 수 있음
```




# 링크

1. [우리는 왜 Spring kafka batch listener를 활용하지 않나요?](https://www.linkedin.com/feed/update/urn:li:activity:7293298871550586882?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7293298871550586882%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29)
2. [Kafka Schema Registry](https://www.linkedin.com/feed/update/urn:li:activity:7290669842167136256/)
3. [분산 시스템 환경에서 Kafka Consumer 오프셋 이동하기](https://helloworld.kurly.com/blog/2024-spring-kafka-consumer-offset-seeking/)
4. [KafkaConsumer Client Internals](https://lnkd.in/djNdQPb6)
2. [KafkaProducer Client Internals](https://lnkd.in/dGCvrf_z)
3. [Kafka NetworkClient Internals](https://lnkd.in/dAsfQ-C4)
4. [Kafka에서 파티션 증가 없이 동시 처리량을 늘리는 방법 - Parallel Consumer](https://lnkd.in/dbvT54x6)
5. [kafka usecase](https://www.linkedin.com/feed/update/urn:li:activity:7168491430456254464?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7168491430456254464%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29)
6. [Apache Avro](https://blog.techeer.net/%EC%B9%B4%ED%94%84%EC%B9%B4-%EB%A9%94%EC%8B%9C%EC%A7%80%EC%97%90-%EC%8A%A4%ED%82%A4%EB%A7%88%EB%A5%BC-%EC%A0%95%EC%9D%98%ED%95%B4-%EB%B3%B4%EC%9E%90-apache-avro-7162e250ae69)
