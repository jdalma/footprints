# 레디스 5장까지

1. 레디스를 캐시 및 세션 스토어로 활용하고, 메시지 브로커로 사용하는 방법
    - 레디스도 서비스간 메시지를 전할 때 매우 유용하게 사용할 수 있다. (pub/sub)
    - fire-and-forget 패턴이 필요한 간단한 알림 서비스에서는 유용하게 사용할 수 있다.
    - 레디스의 List 자료 구조를 통해 데이터가 들어오면 읽어 갈 수 있는 블로킹 기능을 제공한다. 또는 아파치 카프카에 영감을 받아 만들어진 stream 자료 구조도 있다.
    - [레디스 분산 락 Spin Lock과 pub/sub 중 성능이 더 좋은 것은?](https://www.linkedin.com/feed/update/urn:li:activity:7300495152970612736?updateEntityUrn=urn%3Ali%3Afs_updateV2%3A%28urn%3Ali%3Aactivity%3A7300495152970612736%2CFEED_DETAIL%2CEMPTY%2CDEFAULT%2Cfalse%29)
2. NoSQL 데이터 유형
    - 그래프 유형
    - 로우, 컬럼 유형
    - 문서 유형 : JSON
    - 키-값 유형
3. 레디스는 메인 스레드 1개와 별도의 스레드 3개, 총 4개의 스레드로 동작한다.
    - 클라이언트의 커맨드는 1개의 스레드로 처리하니 반환이 느린 특정 커맨드를 주의해서 사용해야한다. (KEYS
4. 레디스의 데이터는 AOF, RDB 형식으로 디스크에 주기적으로 저장할 수 있다.
5. 페이지의 크기를 자동으로 관리하는 THP 기능은 비활성화 하는 것이 좋다
6. 레디스에서 지원하는 자료구조
    - string : 가장 간단한 자료구조, 최대 512MB, 문자열이 binary-safe하게 처리되기 때문에 이미지와 같은 바이트 값, HTTP 응답 값 등의 다양한 데이터를 저장하는 것도 가능하다.
       - bitmap : string 자료구조에 bit 연산을 수행할 수 있도록 확장한 형태
    - list : deque와 비슷한 커맨드를 지원한다
    - hash : 하나의 hash 자료구조 내에서 필드-값 쌍을 가진 아이템의 집합, 하나의 hash 내에서 유일함, 객체를 표현하기 적절한 자료구조이기 때문에 관계형 데이터베이스의 테이블 데이터로 변환하는 것도 간편하다.
    - set : 교집합, 합집합, 차집합 등의 집한 연산 커맨드를 제공
    - sorted-set : score 값에 따라 정렬되는 고유한 문자열의 집합, 모든 아이템은 스코어-값 쌍을 가진다. 인덱스로 접근할 일이 많은 경우 List보다 빠르다. O(log(n))으로 처리됨. 그럼 삽입하거나 삭제할 때 정렬 연산이 포함될 것 같긴함
    - hyperloglog : 집합의 원소 개수인 카디널리티를 측정할 수 있는 자료구조
    - geospatial : 경도, 위도 데이터 쌍의 집합, 내부적으로 sorted-set으로 저장되며, 하나의 자료 구조 안에 키는 중복 저장되지 않는다. (BYRADIUS, BYBOX...)
    - stream : 카프카의 소비자 그룹 개념을 도입해 데이터를 분산 처리할 수 있음, 데이터를 계속해서 추가하는 방식(append-only)으로 저장되므로, 실시간 이벤트 혹은 로그성 데이터의 저장을 위해 사용할 수도 있다.
7. **보통 키 하나당 저장하는 아이템은 최대 200~300만 개까지로 조정할 것을 권장한다.**
8. 사용 사례
    - sorted set : 실시간 리더보드, 최근 검색 기록, 태그 기능
    - set : 좋아요 기능
    - hash : 읽지 않은 메시지 수 카운팅하기, 세션 스토어
    - bitmap : DAU 구하기
    - 랜덤 데이터 추출 (중복 허용 선택 가능)
9. 캐시 워밍
10. 쓰기 전략
    - write through : RDB 데이터가 수정될 때 레디스에 직접 캐시 (만료 시간 설정 필수)
    - cache invalidation : RDB 데이터가 수정될 때 레디스 캐시 데이터 삭제
    - write behind (write back) : 쓰기가 빈번하게 발생하는 환경이라면 캐시에 먼저 업데이트하고 건수나 특정 시간 간격에 따라 비동기적으로 RDB에 업데이트
11. 키 삭제 방식
    - passive 방식 : 키가 만료되었다면 클라이언트가 접근할 때 삭제된다
    - active 방식 : TTL값이 있는 키 중 20개를 랜덤하게 뽑아낸 뒤, 만료된 키를 모두 메모리에서 삭제한다. 만약 25% 이상의 키가 삭제됐다면 다시 20개의 키를 랜덤하게 뽑은 뒤 확인하고, 아니라면 뽑아놓은 20개의 키 집합에서 다시 확인한다. 이러한 과정을 1초에 10번씩 수행한다
12. 메모리 관리와 maxmemory-policy 설정
    - **noeviction** (default) : 메모리가 가득 차더라도 임의로 데이터를 삭제하지 않고 더 이상 저장할 수 없다는 에러를 반환한다.
    - **LRU eviction** : 가장 최근에 사용되지 않은 데이터부터 삭제하는 정책
        - volatile-lru : EXPIRE가 설정돼 있는 키에 한해서 LRU 방식으로 키를 삭제한다. 만료 시간이 설정되어 있다는 것은 언젠가 삭제될 것이기 때문에 가장 오래된 키부터 삭제한다. **임의적인 방식으로 삭제되면 안되는 값에 대해서는 만료 시간을 지정하지 않는다면 이 방법이 적합할 수 있음**
        - allkeys-lru : 모든 키에 대해 LRU 알고리즘을 적용하며 권장되는 방식이다.
    - **LFU eviction** : 가장 자주 사용되지 않은 데이터부터 삭제하는 정책
        - volatile-lfu : EXPIRE가 설정돼 있는 키에 한해서 LFU 방식으로 키를 삭제한다.
        - allkeys-lfu : 모든 키에 대해서 LFU 알고리즘을 적용한다.
    - **Random eviction** : 삭제될 키 값을 계산하지 않고 랜덤으로 하나 골라 삭제한다. 권장하지 않는다.
    - **volatile-ttl** : 만료 시간이 가장 작은 키를 삭제한다.
13. 캐시 스탬피드 현상
    - look aside 읽기 방식에서 캐시 미스가 발생하였을 때 RDB에서 '중복 읽기'와 캐시 '중복 쓰기'가 발생하는 현상을 말한다.
    - **적절한 만료시간 설정** : 너무 짧지 않게 설정
    - **선 계산** : 캐시 히트가 발생하였을 때 랜덤으로 키의 만료시간을 갱신한다.
    - **PER 알고리즘**

# 레디스 끝까지

1. **메시지 브로커의 핵심** : 통신이 불가능한 상황이 바로 장애로 이어지지 않게, 메시지 버퍼 역할인 채널을 만듦. 가능한 비동기 통신을 사용하는 것
    - 메시징 큐 : 큐에 각각 데이터를 푸시해야함. 소비자가 데이터를 읽어가면 큐에서 데이터를 삭제함. 1:1 상황에서 유리함.
        - **레디스의 pub/sub** : `fire-and-forget` 패턴이 필요한 간단한 알림 서비스에서는 유용할 수 있다. (로깅, 이벤트 발행, 통계 데이터 수집 등)    
    - 이벤트 스트림 : 특정 저장소에 메시지를 보내고 소비자가 pull 해감. 소비자가 읽어가도 바로 삭제하지 않고 특정 기간동안 저장될 수 있음. N:N 상황에서 유리함 (ex 코틀린의 Flow)
        - **레디스의 stream** : 소비지와 소비자 그룹이라는 개념을 이용하면 카프카에서와 비슷하게 데이터의 분산 처리 가능. 실시간 소비 또는 시간대별로 검색 가능
2. 트위터는 각 유저의 타임라인 캐시 데이터를 레디스에서 list 자료구조로 관리한다.
    - B,C가 A를 팔로우하고 있을 때 A가 글을 작성하면 B와 C의 list에 새로운 아이템으로 추가한다. RPUSHX 커맨드로 list가 존재하는 사용자에게만 푸시한다.
3. Stream
    - `append-only`
    - 대량의 데이터를 효율적으로 처리할 수 있는 플랫폼으로 활용 가능
    - 여러 생산자가 생성한 데이터를 다양한 소비자가 처리할 수 있게 지원하는 데이터 저장소 및 중간 큐잉 시스템으로 사용 가능
    - 다른 자료구조와 마찬가지로 하나의 키에 연결된 자료구조다.
    - 각 메시지는 시간과 관련된 유니크한 ID를 가지며, 이 값은 중복되지 않는다. `<milliseoncdsTime>-<sequenceNumber>`
    - 데이터는 hash 자료구조 처럼 '필드-값'쌍으로 저장된다.
    - **소비자가 실시간 리스닝**
    - **ID를 이용해 필요한 데이터를 검색**
4. **팬아웃** : 같은 데이터를 여러 소비자에게 전달하는 것
    - 레디스는 데이터가 저장될 때마다 고유한 ID를 부여받아 순서대로 공급하기에, 소비자에게 순서가 항상 보장된다. 레디스의 소비자 그룹은 다른 소비자가 읽지 않은 데이터만 읽어가도록 설정하는 것이다.
        - 하나의 소비자 그룹에서 여러 stream을 리스닝하는 것도 가능하고, 하나의 stream에서 여러 소비자 그룹이 리스닝하는 것도 가능하다.
    - 카프카는 파티션 내에서만 유니크 키가 보장되기 때문에 소비자가 여러 파티션에서 토픽을 읽어갈 때에는 데이터의 순서를 보장할 수 없다. 토픽 내의 파티션과 소비자를 일대일로 연결하기 위해 소비자 그룹을 설정하여 순서를 보장할 수 있다.
    - **카프카가 파티션이라는 개념을 이용해 소비자의 부하 분산을 관리한다면 레디스의 stream은 파티션이라는 분할 없이도 소비자 그룹이라는 개념을 이용해 여러 소비자에게 stream의 데이터를 분산시킬 수 있다는 특징을 갖고 있다.**
5. **ACK와 보 리스트**
    - 소비자에게 장애가 발생한 경우, 재처리를 위해 메시지 브로커는 각 소비자에게 어떤 메시지까지 전달했고, 전달된 메시지의 처리 유무를 인지하고 있어야 한다.
    - 레디스 stream에서는 소비자 그룹에 속한 소비자가 메시지를 읽어가면 각 소비자별로 읽어간 메시지에 대한 리스트를 새로 생성하며, 마지막으로 읽어간 데이터의 ID로 `last_delivered_id`값을 업데이트한다. 소비자가 ACK를 전송하면 이 ID 값이 증가한다.
7. `as most once` vs `as least once` vs `exactly once`
8. 레디스의 최초 동기 복제 메커니즘은 클라이언트가 마스터에게 요청하며 RDB 스냅숏 + RESP 형태로 진행된다.
    - 정상적으로 복제 연결이 완료되면 마스터는 읽기 전용에게 데이터를 비동기 방식으로 전달한다.
    - 복제 연결이 끊긴 경우에는 부분 재동기화가 가능하다.
9. 센티널
    - 자동 페일오버와 인스턴스 구성 정보 안내를 통해 마스터에 장애가 발생하더라도 다운타임을 최소화해준다.
    - 쿼럼을 기준으로 승격할 마스터를 정하기 때문에 홀수의 서버가 필요하지만 최소한으로 2대의 정상적인 서버, 센티넬과 1대의 센티넬만 구성하여 운영할 수도 있다.
    - 일시적인 네트워크 단절로 인한 두 개의 마스터가 생성될 수 있디. (스플릿 브레인 문제)
10. 클러스터
    - 각각 최소 3대의 마스터, 복제본 노드
    - 각 노드들은 풀 메쉬 토폴로지 형태로 구성되어 있으며, 모든 노드는 N-1개의 다른 노드와 송수신 TCP 연결이 되어 있다.
    - 서로 다른 해시슬롯에 속한 키에 대해서는 다중 키 커맨드를 사용할 수 없지만 해시태그를 이용해서 처리할 수 있다.
11. 클라이언트
    - 멀티플렉싱 방식을 사용하기에 하나의 통신 채널을 통해 여러 데이터 스트림을 전송할 수 있다.
    - 하나의 스레드에서 여러 소켓을 감시하고, 소켓 이벤트가 발생하는지 지속적으로 확인할 수 있기 때문에 다중 클라이언트 지원을 가능하게하고, 많은 클라이언트 요청을 동시에 처리하는데 블로킹 문제를 피할 수 있다.
      일반 클라이언트, pub/sub 클라이언트, 복제본을 위한 출력 버퍼 크기가 모두 다르게 적용된다.
    - **파이프라이닝**
        - 클라이언트가 연속적으로 여러 개의 커맨드를 레디스 서버에 보낼 수 있도록 하는 기능
    - **클라이언트 사이드 캐싱**

# 무지목록

1. list의 블로킹은 BRPOP, BLPOP으로 여러 개의 큐에 대한 데이터 감지를 하도록 명령할 수 있는데 레디스에 성능적으로 영항은 없는것인가?
2. 카프카의 파티션을 여러 개 분리해서 사용하지 않는다면 레디스 stream을 선택하는 것이 좋을까?
